\subsection{The NTNU Cyborg Project}
The NTNU cyborg project is a collaboration between several departments at NTNU
including the department of biotechnology, computer and information science,
engineering cybernetics, neuroscience and more. \cite{fossen_ntnu_???}
The stated goal for the cyborg project is ``to enable communication between living
nerve tissue and a robot. The social and interactive cyborg will walk around the campus
raising awareness for biotechnology and ICT, bringing NTNU in the forefront of research
and creating a platform for interdisciplinary collaborations and teaching.''
Currently the department of neuroscience is growing neuron cultures which are to
be used as the biological part of the robot.
These neuron cultures are not part of a brain, they are fully dissociated, grown
in special chambers in-vitro.
The robot part of the cyborg has been developed and implemented by the
department of engineering cybernetics, and is currently operational, however it
has not yet been integrated with the in-vitro neuron cultures.
The challenge faced by the cyborg project is the infrastructure for interfacing the
neuron cultures and the robot, essentially creating a brain computer interface.
\subsection{Complex Systems}
\textit{
  In this paper references are made to computations done by both artificial and real
  neurons.
  To make the distinction between these cases clear all computation done by
  computer simulated approximations of neurons will be prefixed as artificial.
}\\
The self-organizing properties that makes cellular computing a such a successful
paradigm in nature also make understanding and exploiting them difficult.
Many such systems have been explored, such as recurrent artificial neural
networks \cite{bertschinger_real-time_2004}, random boolean networks
\cite{gershenson_introduction_2004} and cellular automata.
In \cite{langton_computation_1990} Langton explores the requirements for systems
to support emergent computation, where
he argues that in order for a system to support emergent computation it must
lie in a \textit{critical phase} between order and chaos, drawing parallels to
phase transitions in material science.
This observation comes from thermodynamics, in which a material may exhibit a
\textit{second order phase transition} between a solid and liquid form where the
material undergoes a continuous transition in contrast to a first order
transition such as melting ice.
Using cellular automata as an example, he explores the effect of varying the
rules for calculating the next state with a parameter, $\lambda$, which
describes how likely it is for a cell to enter a \textit{quiescent state}, a state
where it will not disturb other cells until it leaves the quiescent state itself.
At $\lambda = 0$ all cells enter a quiescent state after one step, representing
a fully ordered system, thus at $\lambda = 0$ the system is in the ordered phase.
At $\lambda = 1$ there are no rules that leads to a quiescent state, leading to
very chaotic systems with very high entropy, representing the chaotic phase.
As $\lambda$ is increased from 0 the cellular systems starts to form intricate
structures, increasing in complexity and taking longer to reach a steady state.
This behavior peaks at $\lambda \approx 0.5$ which is the most critical phase in this
particular system, creating complex self-organizing structures.
As $\lambda$ is increased further the self-organizing structures start to give
way to more chaotic and seemingly random behavior, gradually transitioning into
the chaotic phase.\\
It turns out then, that with most cellular systems providing the necessary
conditions for computation to occur is a tractable problem, however harnessing
and shaping this computation is a whole different matter.
In their critical phase systems are unstable but not chaotic which causes them to
be highly sensitive to small changes in topology and initial conditions.
Attempting to maneuver this fitness-landscape by directly changing the
properties of a system would in many ways be like calculating the correct way
for a butterfly in china to flap its wings in order to cause a hurricane in New York.\\
\subsection{Reservoir Computing}
Faced with the intractability of designing cellular computation systems in a top
down manner, and the unpredictable relation between cause and effect in self organizing
systems has made it necessary to approach complex systems in a different manner.
One such approach is to treat the system as a \textit{reservoir}
\cite{schrauwen_overview_2007} which
``acts as a complex nonlinear dynamic filter that transforms the
input signals using a high-dimensional temporal map, not unlike the operation
of an explicit, temporal kernel function.''\\
AAAAAA
\ref{fig:RC} shows a typical RC (reservoir computing) system with three inputs
and two outputs. The inputs are processed in a simple feed-forward neural
network before perturbing the reservoir in some way.
Similarly the state of the reservoir is being processed by an output layer
before leaving the RC system.
In the figure the input and output processing is done by feed forward neural
networks, but we note that this is only one of many possible filters.
Inputs 1, 2 and 3 are snapshots of the current state of the problem we attempt
to solve with reservoir computing.
Since our filters have no state, at least not beyond some time horizon we see
that the history of the system must in some way be encoded in the reservoir in
order for the RC system to solve problems in scope wider than the limited amount
of state that may be contained in the filters.
\begin{figure*}[h]
  \input{latex/tikz}
  \caption{A reservoir comput-thingy}
  \label{fig:RC}
\end{figure*}
\subsection{Neuron Computing}
The human brain consist of 100 billion neurons, forming a vastly complex
hierarchy of behavior, from the neuron-level interactions to the interaction
between different parts of the brain such as the hippocampus and the frontal lobe.
The basic building block of the brain is the neuron, which even by itself is a
very complex system, not at all analogous to a single transistor or an artificial
neuron.
These neurons communicate with each others using electric and chemical signals
in a complex interplay between neurotransmitters, voltage spikes and even
rearranging their physical structures, growing new connections and letting
unused connections wither.
The complexities of neurons have been widely studied, but for this paper a
cursory introduction is sufficient.
We will only consider a generalized version of the neuron, but in our
experiments a plethora of different neurons are used, although they
all share the basic similarities described here.
The anatomy of a neuron is shown in \ref{fig:neuron_anatomy} and can roughly be
divided into the following parts:
\subsubsection{Soma}
The main body of the neuron.
\subsubsection{Dendrites}
To sense its surroundings the neuron is equipped with dendrites. These
branching structures act as receivers, propagating electro-chemical stimuli to
the cell body. Their reach is only to the immediate vicinity of the cell, they
do not form longer connections.
\subsubsection{Axon}
The axon is a long tendril, extending over a meter in the case of the sciatic
nerve, which transmits information as electrical pulses to other neurons. An
axon can branch off and reach multiple neurons, it is not a one to one
connection.
\subsection{Adaptivity}
Write about evolvable systems. Possibly evo-devo?
Something in relation to understanding the underlying growth rules (devo) using
evolution, in contrast to directly evolving phenotypes.

\begin{figure*}[p]
    \centering
    \includegraphics[width=\textwidth]{images/"Neuron anatomy".png}
    \caption{a neuron}
    \label{fig:neuron_anatomy}
\end{figure*}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
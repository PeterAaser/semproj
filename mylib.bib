
@article{li_application_2015,
  title = {Application of {{Hierarchical Dissociated Neural Network}} in {{Closed}}-{{Loop Hybrid System Integrating Biological}} and {{Mechanical Intelligence}}},
  volume = {10},
  issn = {1932-6203},
  url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0127452},
  doi = {10.1371/journal.pone.0127452},
  abstract = {Neural networks are considered the origin of intelligence in organisms. In this paper, a new design of an intelligent system merging biological intelligence with artificial intelligence was created. It was based on a neural controller bidirectionally connected to an actual mobile robot to implement a novel vehicle. Two types of experimental preparations were utilized as the neural controller including ‘random’ and ‘4Q’ (cultured neurons artificially divided into four interconnected parts) neural network. Compared to the random cultures, the ‘4Q’ cultures presented absolutely different activities, and the robot controlled by the ‘4Q’ network presented better capabilities in search tasks. Our results showed that neural cultures could be successfully employed to control an artificial agent; the robot performed better and better with the stimulus because of the short-term plasticity. A new framework is provided to investigate the bidirectional biological-artificial interface and develop new strategies for a future intelligent system using these simplified model systems.},
  timestamp = {2016-12-02T13:42:50Z},
  number = {5},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  author = {Li, Yongcheng and Sun, Rong and Zhang, Bin and Wang, Yuechao and Li, Hongyi},
  urldate = {2016-12-02},
  date = {2015-05-19},
  pages = {e0127452},
  keywords = {Action potentials,Electrode recording,Functional electrical stimulation,Graphical user interface,Intelligence,Neural networks,Neurons,Robots},
  file = {Full Text PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/F5645BUZ/Li et al. - 2015 - Application of Hierarchical Dissociated Neural Net.pdf:application/pdf;Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/T4TE3UPP/article.html:text/html}
}

@article{natschlager_liquid_2002,
  title = {The "{{Liquid Computer}}" {{A Novel Strategy}} for {{Real}}-{{Time Computing}} on {{Time Series}}},
  volume = {8},
  url = {https://infoscience.epfl.ch/record/117806},
  shorttitle = {The \&quot;{{Liquid Computer}}\&quot;},
  timestamp = {2016-12-07T16:34:41Z},
  number = {1},
  journaltitle = {Special Issue on Foundations of Information Processing of TELEMATIK},
  author = {Natschläger, T. and Maass, W. and Markram, H.},
  urldate = {2016-12-07},
  date = {2002},
  pages = {39--43},
  file = {143.pdf:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/U9U42JRZ/143.pdf:application/pdf;Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/SM9C8FWI/117806.html:text/html}
}

@inproceedings{schrauwen_overview_2007,
  title = {An Overview of Reservoir Computing: {{Theory}}, Applications and Implementations},
  url = {https://www.researchgate.net/publication/221166209_An_overview_of_reservoir_computing_Theory_applications_and_implementations},
  shorttitle = {An Overview of Reservoir Computing},
  abstract = {Training recurrent neural networks is hard. Recently it has however been discovered that it is possible to just construct a random recurrent topology, and only train a single linear readout layer....},
  eventtitle = {ESANN 2007, 15th European Symposium on Artificial Neural Networks, Bruges, Belgium, April 25-27, 2007, Proceedings},
  timestamp = {2016-12-04T15:55:46Z},
  booktitle = {{{ResearchGate}}},
  author = {Schrauwen, Benjamin and Verstraeten, David and Campenhout, Jan M. Van},
  urldate = {2016-12-04},
  date = {2007-01-01},
  pages = {471--482},
  file = {es2007-8.pdf:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/GURMZRDN/es2007-8.pdf:application/pdf;Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/SUKA4I4S/221166209_An_overview_of_reservoir_computing_Theory_applications_and_implementations.html:text/html}
}

@article{garnier_biological_2007,
  title = {The Biological Principles of Swarm Intelligence},
  volume = {1},
  issn = {1935-3812, 1935-3820},
  url = {http://link.springer.com/article/10.1007/s11721-007-0004-y},
  doi = {10.1007/s11721-007-0004-y},
  abstract = {The roots of swarm intelligence are deeply embedded in the biological study of self-organized behaviors in social insects. From the routing of traffic in telecommunication networks to the design of control algorithms for groups of autonomous robots, the collective behaviors of these animals have inspired many of the foundational works in this emerging research field. For the first issue of this journal dedicated to swarm intelligence, we review the main biological principles that underlie the organization of insects’ colonies. We begin with some reminders about the decentralized nature of such systems and we describe the underlying mechanisms of complex collective behaviors of social insects, from the concept of stigmergy to the theory of self-organization in biological systems. We emphasize in particular the role of interactions and the importance of bifurcations that appear in the collective output of the colony when some of the system’s parameters change. We then propose to categorize the collective behaviors displayed by insect colonies according to four functions that emerge at the level of the colony and that organize its global behavior. Finally, we address the role of modulations of individual behaviors by disturbances (either environmental or internal to the colony) in the overall flexibility of insect colonies. We conclude that future studies about self-organized biological behaviors should investigate such modulations to better understand how insect colonies adapt to uncertain worlds.},
  timestamp = {2016-12-04T15:49:16Z},
  langid = {english},
  number = {1},
  journaltitle = {Swarm Intelligence},
  shortjournal = {Swarm Intell},
  author = {Garnier, Simon and Gautrais, Jacques and Theraulaz, Guy},
  urldate = {2016-12-04},
  date = {2007-06-01},
  pages = {3--31},
  file = {Full Text PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/DS8CRRQZ/Garnier et al. - 2007 - The biological principles of swarm intelligence.pdf:application/pdf;Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/HBI3H3VA/s11721-007-0004-y.html:text/html}
}

@article{heylighen_science_1970,
  title = {The {{Science Of Self}}-{{Organization And Adaptivity}}},
  volume = {5},
  url = {https://www.researchgate.net/publication/2817974_The_Science_Of_Self-Organization_And_Adaptivity},
  abstract = {this paper by the Fund for Scientific Research-Flanders (FWO), as a Senior Research Associate.},
  timestamp = {2016-12-04T16:01:20Z},
  number = {3},
  journaltitle = {ResearchGate},
  author = {Heylighen, Francis},
  urldate = {2016-12-04},
  date = {1970-02-01},
  file = {Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/KV8RZEXS/2817974_The_Science_Of_Self-Organization_And_Adaptivity.html:text/html}
}

@online{fossen_ntnu_????,
  title = {{{NTNU Cyborg}}},
  url = {https://www.ntnu.edu/cyborg},
  timestamp = {2016-12-08T10:39:29Z},
  langid = {english},
  author = {Fossen, Christian},
  urldate = {2016-12-08},
  file = {Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/UGX9V429/cyborg.html:text/html}
}

@inproceedings{demarse_adaptive_2005,
  title = {Adaptive Flight Control with Living Neuronal Networks on Microelectrode Arrays},
  volume = {3},
  doi = {10.1109/IJCNN.2005.1556108},
  abstract = {The brain is perhaps one of the most robust and fault tolerant computational devices in existence and yet little is known about its mechanisms. Microelectrode arrays have recently been developed in which the computational properties of networks of living neurons can be studied in detail. In this paper we report work investigating the ability of living neurons to act as a set of neuronal weights which were used to control the flight of a simulated aircraft. These weights were manipulated via high frequency stimulation inputs to produce a system in which a living neuronal network would "learn" to control an aircraft for straight and level flight.},
  eventtitle = {Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.},
  timestamp = {2016-12-05T15:06:54Z},
  booktitle = {Proceedings. 2005 {{IEEE International Joint Conference}} on {{Neural Networks}}, 2005.},
  author = {DeMarse, T. B. and Dockendorf, K. P.},
  date = {2005-07},
  pages = {1548--1551 vol. 3},
  keywords = {Adaptive arrays,adaptive control,adaptive flight control,aerospace control,aerospace simulation,Aircraft,aircraft flight control,Biological neural networks,control engineering computing,Fault tolerance,fault tolerant computational device,flight simulation,learning (artificial intelligence),living neuronal network,microelectrode array,Microelectrodes,neurocontrollers,Neurons,Programmable control,Robustness},
  file = {IEEE Xplore Full Text PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/534J5PXU/DeMarse and Dockendorf - 2005 - Adaptive flight control with living neuronal netwo.pdf:application/pdf;IEEE Xplore Abstract Record:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/MF7M3BTP/1556108.html:text/html}
}

@online{_feminist_????,
  title = {Feminist {{Frequency}}},
  url = {https://feministfrequency.com/},
  abstract = {Conversations with pop culture},
  timestamp = {2016-12-07T16:07:45Z},
  urldate = {2016-12-07},
  keywords = {con,random noise,sjw,swindle,trigger},
  file = {Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/SZ8MQAU2/feministfrequency.com.html:text/html}
}

@article{langton_computation_1990,
  title = {Computation at the Edge of Chaos: {{Phase}} Transitions and Emergent Computation},
  volume = {42},
  issn = {0167-2789},
  url = {http://www.sciencedirect.com/science/article/pii/016727899090064V},
  doi = {10.1016/0167-2789(90)90064-V},
  shorttitle = {Computation at the Edge of Chaos},
  abstract = {In order for computation to emerge spontaneously and become an important factor in the dynamics of a system, the material substrate must support the primitive functions required for computation: the transmission, storage, and modification of information. Under what conditions might we expect physical systems to support such computational primitives? This paper presents research on cellular automata which suggests that the optimal conditions for the support of information transmission, storage, and modification, are achieved in the vicinity of a phase transition. We observe surprising similarities between the behaviors of computations and systems near phase transitions, finding analogs of computational complexity classes and the halting problem within the phenomenology of phase transitions. We conclude that there is a fundamental connection between computation and phase transitions, especially second-order or “critical” transitions, and discuss some of the implications for our understanding of nature if such a connection is borne out.},
  timestamp = {2016-12-05T12:49:11Z},
  number = {1},
  journaltitle = {Physica D: Nonlinear Phenomena},
  shortjournal = {Physica D: Nonlinear Phenomena},
  author = {Langton, Chris G.},
  urldate = {2016-12-05},
  date = {1990-06-01},
  pages = {12--37},
  file = {1-s2.0-016727899090064V-main.pdf:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/6MN3Q9RR/1-s2.0-016727899090064V-main.pdf:application/pdf;ScienceDirect Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/CEED92BV/016727899090064V.html:text/html}
}

@article{muller_high-resolution_2015,
  title = {High-Resolution {{CMOS MEA}} Platform to Study Neurons at Subcellular, Cellular, and Network Levels},
  issn = {1473-0189},
  url = {/article/dr000000011169},
  doi = {10.1039/C5LC00133A},
  abstract = {Studies on information processing and learning properties of neuronal networks would benefit from simultaneous and parallel access to the activity of a large fraction of all neurons in such networks. Here we present a CMOS-based device, capable of simultaneously recording the electrical activity of over a thous...},
  timestamp = {2016-12-06T17:04:35Z},
  langid = {english},
  journaltitle = {Lab Chip},
  shortjournal = {Lab Chip},
  author = {Müller, Jan and Ballini, Marco and Livi, Paolo and Chen, Yihui and Radivojevic, Milos and Shadmani, Amir and Viswam, Vijay and Jones, Ian L. and Fiscella, Michele and Diggelmann, Roland and Stettler, Alexander and Frey, Urs and Hierlemann, Douglas J. Bakkum and Andreas},
  urldate = {2016-12-05},
  date = {2015-05-07},
  file = {Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/C57NT8EM/dr000000011169.html:text/html}
}

@article{sipper_emergence_1999,
  title = {The Emergence of Cellular Computing},
  volume = {32},
  issn = {0018-9162},
  doi = {10.1109/2.774914},
  abstract = {The von Neumann architecture-which is based upon the principle of one complex processor that sequentially performs a single complex task at a given moment-has dominated computing technology for the past 50 years. Recently however, researchers have begun exploring alternative computational systems based on entirely different principles. Although emerging from disparate domains, the work behind these systems shares a common computational philosophy, which the author calls cellular computing. This philosophy promises to provide new means for doing computation more efficiently-in terms of speed, cost, power dissipation, information storage, and solution quality. Simultaneously, cellular computing offers the potential of addressing much larger problem instances than previously possible, at least for some application domains. Cellular computing has attracted increasing research interest. Work in this field has produced results that hold prospects for a bright future. Yet questions must be answered before cellular computing can become a mainstream paradigm. What classes of computational tasks are most suited to it? How do we match the specific properties and behaviors of a given model to a suitable class of problems? At its heart, cellular computing consists of three principles: simplicity, vast parallelism, and locality},
  timestamp = {2016-12-09T15:29:30Z},
  number = {7},
  journaltitle = {Computer},
  author = {Sipper, M.},
  date = {1999-07},
  pages = {18--26},
  keywords = {alternative computational systems,cellular arrays,cellular computing,Centralized control,computational tasks,Computer architecture,Concurrent computing,Control systems,Costs,Heart,large problem instances,locality,parallelism,parallel processing,Physics computing,Power dissipation,Turing machines},
  file = {IEEE Xplore Full Text PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/QT478XZT/Sipper - 1999 - The emergence of cellular computing.pdf:application/pdf;IEEE Xplore Abstract Record:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/M8C4IN6H/774914.html:text/html}
}

@article{massobrio_vitro_2015-1,
  title = {In {{Vitro Studies}} of {{Neuronal Networks}} and {{Synaptic Plasticity}} in {{Invertebrates}} and in {{Mammals Using Multielectrode Arrays}}},
  volume = {2015},
  issn = {2090-5904},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4381683/},
  doi = {10.1155/2015/196195},
  abstract = {Brain functions are strictly dependent on neural connections formed during development and modified during life. The cellular and molecular mechanisms underlying synaptogenesis and plastic changes involved in learning and memory have been analyzed in detail in simple animals such as invertebrates and in circuits of mammalian brains mainly by intracellular recordings of neuronal activity. In the last decades, the evolution of techniques such as microelectrode arrays (MEAs) that allow simultaneous, long-lasting, noninvasive, extracellular recordings from a large number of neurons has proven very useful to study long-term processes in neuronal networks in vivo and in vitro. In this work, we start off by briefly reviewing the microelectrode array technology and the optimization of the coupling between neurons and microtransducers to detect subthreshold synaptic signals. Then, we report MEA studies of circuit formation and activity in invertebrate models such as Lymnaea, Aplysia, and Helix. In the following sections, we analyze plasticity and connectivity in cultures of mammalian dissociated neurons, focusing on spontaneous activity and electrical stimulation. We conclude by discussing plasticity in closed-loop experiments.},
  timestamp = {2016-12-05T15:09:04Z},
  journaltitle = {Neural Plasticity},
  shortjournal = {Neural Plast},
  author = {Massobrio, Paolo and Tessadori, Jacopo and Chiappalone, Michela and Ghirardi, Mirella},
  urldate = {2016-12-05},
  date = {2015},
  file = {PubMed Central Full Text PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/BG5598ZX/Massobrio et al. - 2015 - In Vitro Studies of Neuronal Networks and Synaptic.pdf:application/pdf},
  eprinttype = {pmid},
  eprint = {25866681},
  pmcid = {PMC4381683}
}

@article{lukosevicius_reservoir_2012,
  title = {Reservoir {{Computing Trends}}},
  volume = {26},
  issn = {0933-1875, 1610-1987},
  url = {http://link.springer.com/article/10.1007/s13218-012-0204-5},
  doi = {10.1007/s13218-012-0204-5},
  abstract = {Reservoir Computing (RC) is a paradigm of understanding and training Recurrent Neural Networks (RNNs) based on treating the recurrent part (the reservoir) differently than the readouts from it. It started ten years ago and is currently a prolific research area, giving important insights into RNNs, practical machine learning tools, as well as enabling computation with non-conventional hardware. Here we give a brief introduction into basic concepts, methods, insights, current developments, and highlight some applications of RC.},
  timestamp = {2016-12-07T16:32:54Z},
  langid = {english},
  number = {4},
  journaltitle = {KI - Künstliche Intelligenz},
  shortjournal = {Künstl Intell},
  author = {Lukoševičius, Mantas and Jaeger, Herbert and Schrauwen, Benjamin},
  urldate = {2016-12-07},
  date = {2012-11-01},
  pages = {365--371},
  file = {Full Text PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/B9DRIB2S/Lukoševičius et al. - 2012 - Reservoir Computing Trends.pdf:application/pdf;Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/4BTQZ7KU/s13218-012-0204-5.html:text/html}
}

@article{demarse_neurally_2001,
  title = {The {{Neurally Controlled Animat}}: {{Biological Brains Acting}} with {{Simulated Bodies}}},
  volume = {11},
  issn = {0929-5593},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2440704/},
  shorttitle = {The {{Neurally Controlled Animat}}},
  abstract = {The brain is perhaps the most advanced and robust computation system known. We are creating a method to study how information is processed and encoded in living cultured neuronal networks by interfacing them to a computer-generated animal, the Neurally-Controlled Animat, within a virtual world. Cortical neurons from rats are dissociated and cultured on a surface containing a grid of electrodes (multi-electrode arrays, or MEAs) capable of both recording and stimulating neural activity. Distributed patterns of neural activity are used to control the behavior of the Animat in a simulated environment. The computer acts as its sensory system providing electrical feedback to the network about the Animat’s movement within its environment. Changes in the Animat’s behavior due to interaction with its surroundings are studied in concert with the biological processes (e.g., neural plasticity) that produced those changes, to understand how information is processed and encoded within a living neural network. Thus, we have created a hybrid real-time processing engine and control system that consists of living, electronic, and simulated components. Eventually this approach may be applied to controlling robotic devices, or lead to better real-time silicon-based information processing and control algorithms that are fault tolerant and can repair themselves.},
  timestamp = {2016-12-05T15:05:08Z},
  number = {3},
  journaltitle = {Autonomous robots},
  shortjournal = {Auton Robots},
  author = {DeMARSE, THOMAS B. and WAGENAAR, DANIEL A. and BLAU, AXEL W. and POTTER, STEVE M.},
  urldate = {2016-12-05},
  date = {2001},
  pages = {305--310},
  file = {PubMed Central Full Text PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/I2KJCSHM/DeMARSE et al. - 2001 - The Neurally Controlled Animat Biological Brains .pdf:application/pdf},
  eprinttype = {pmid},
  eprint = {18584059},
  pmcid = {PMC2440704}
}

@article{bertschinger_real-time_2004,
  title = {Real-Time Computation at the Edge of Chaos in Recurrent Neural Networks},
  volume = {16},
  issn = {0899-7667},
  doi = {10.1162/089976604323057443},
  abstract = {Depending on the connectivity, recurrent networks of simple computational units can show very different types of dynamics, ranging from totally ordered to chaotic. We analyze how the type of dynamics (ordered or chaotic) exhibited by randomly connected networks of threshold gates driven by a time-varying input signal depends on the parameters describing the distribution of the connectivity matrix. In particular, we calculate the critical boundary in parameter space where the transition from ordered to chaotic dynamics takes place. Employing a recently developed framework for analyzing real-time computations, we show that only near the critical boundary can such networks perform complex computations on time series. Hence, this result strongly supports conjectures that dynamical systems that are capable of doing complex computational tasks should operate near the edge of chaos, that is, the transition from ordered to chaotic dynamics.},
  timestamp = {2016-12-05T11:49:21Z},
  langid = {english},
  number = {7},
  journaltitle = {Neural Computation},
  shortjournal = {Neural Comput},
  author = {Bertschinger, Nils and Natschläger, Thomas},
  date = {2004-07},
  pages = {1413--1436},
  keywords = {Animals,Artificial Intelligence,Computer Simulation,Feedback,Memory,Models; Neurological,Neural Networks (Computer),Nonlinear Dynamics,Time Factors},
  eprinttype = {pmid},
  eprint = {15165396}
}

@incollection{warwick_experiments_2011,
  title = {Experiments with an {{In}}-{{Vitro Robot Brain}}},
  url = {http://link.springer.com/chapter/10.1007/978-3-642-19757-4_1},
  abstract = {The controlling mechanism of a typical mobile robot is usually a computer system either remotely positioned or in-body. Recent research is on-going in which biological neurons are grown and trained to act as the brain of an interactive real-world robot – thereby acting as instinctive computing elements. Studying such a system provides insights into the operation of biological neural structures; therefore, such research has immediate medical implications as well as enormous potential in computing and robotics. A system involving closed-loop control of a mobile robot by a culture of neurons has been created. This article provides an overview of the problem area, gives an idea of the breadth of present ongoing research, details our own system architecture and, in particular, reports on the results of experiments with real-life robots. The authors see this as a new form of artificial intelligence.},
  timestamp = {2016-12-08T11:05:22Z},
  langid = {english},
  booktitle = {Computing with {{Instinct}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {Warwick, Kevin and Nasuto, Slawomir J. and Becerra, Victor M. and Whalley, Benjamin J.},
  urldate = {2016-12-08},
  date = {2011},
  pages = {1--15},
  file = {Full Text PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/WCXGNVU4/Warwick et al. - 2011 - Experiments with an In-Vitro Robot Brain.pdf:application/pdf;Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/PGFV926E/10.html:text/html},
  doi = {10.1007/978-3-642-19757-4_1}
}

@inproceedings{bull_initial_2007,
  location = {{New York, NY, USA}},
  title = {Initial {{Results}} from the {{Use}} of {{Learning Classifier Systems}} to {{Control}} in {{Vitro Neuronal Networks}}},
  isbn = {978-1-59593-697-4},
  url = {http://doi.acm.org/10.1145/1276958.1277036},
  doi = {10.1145/1276958.1277036},
  abstract = {In this paper we describe the use of a learning classifier system to control the electrical stimulation of cultured neuronal networks. The aim is to manipulate the environment of the cells such that they display elementary learning, i.e., so that they respond to a given input signal in a pre-specified way. Results indicate that this is possible and that the learned stimulation protocols identify seemingly fundamental properties of in vitro neuronal networks.allUse of another learning scheme and simpler stimulation confirms these properties.},
  timestamp = {2016-12-05T15:04:48Z},
  booktitle = {Proceedings of the 9th {{Annual Conference}} on {{Genetic}} and {{Evolutionary Computation}}},
  series = {GECCO '07},
  publisher = {{ACM}},
  author = {Bull, Larry and Uroukov, Ivan S.},
  urldate = {2016-12-05},
  date = {2007},
  pages = {369--376},
  keywords = {multi-electrode array,unconventional computation,XCS},
  file = {ACM Full Text PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/WDCXGWI5/Bull and Uroukov - 2007 - Initial Results from the Use of Learning Classifie.pdf:application/pdf}
}

@article{tufte_evo_2009,
  title = {From {{Evo}} to {{EvoDevo}}: {{Mapping}} and {{Adaptation}} in {{Artificial Development}}},
  url = {http://www.intechopen.com/books/evolutionary-computation/from-evo-to-evodevo-mapping-and-adaptation-in-artificial-development},
  doi = {10.5772/9603},
  shorttitle = {From {{Evo}} to {{EvoDevo}}},
  abstract = {From Evo to EvoDevo: Mapping and Adaptation in Artificial Development | InTechOpen, Published on: 2009-10-01. Authors: Gunnar Tufte},
  timestamp = {2016-12-10T13:39:25Z},
  langid = {english},
  author = {Tufte, Gunnar},
  urldate = {2016-12-10},
  date = {2009},
  file = {Full Text PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/NWNG3WI7/Tufte - 2009 - From Evo to EvoDevo Mapping and Adaptation in Art.pdf:application/pdf;Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/M7XIBM7Z/from-evo-to-evodevo-mapping-and-adaptation-in-artificial-development.html:text/html}
}

@article{doursat_review_2013,
  title = {A Review of Morphogenetic Engineering},
  volume = {12},
  issn = {1567-7818, 1572-9796},
  url = {http://link.springer.com/article/10.1007/s11047-013-9398-1},
  doi = {10.1007/s11047-013-9398-1},
  abstract = {Generally, phenomena of spontaneous pattern formation are random and repetitive, whereas elaborate devices are the deterministic product of human design. Yet, biological organisms and collective insect constructions are exceptional examples of complex systems (CS) that are both architectured and self-organized. Can we understand their precise self-formation capabilities and integrate them with technological planning? Can physical systems be endowed with information, or informational systems be embedded in physics, to create autonomous morphologies and functions? To answer these questions, we have launched in 2009, and developed through a series of workshops and a collective book, a new field of research called morphogenetic engineering. It is the first initiative of its kind to rally and promote models and implementations of complex self-architecturing systems. Particular emphasis is set on the programmability and computational abilities of self-organization, properties that are often underappreciated in CS science—while, conversely, the benefits of self-organization are often underappreciated in engineering methodologies. [This paper is an extended version of Doursat, Sayama and Michel (2012b) (Chapter 1, in Doursat R et al. (eds.) Morphogenetic engineering: toward programmable complex systems. Understanding complex systems. Springer, 2012a).]},
  timestamp = {2016-12-08T11:47:37Z},
  langid = {english},
  number = {4},
  journaltitle = {Natural Computing},
  shortjournal = {Nat Comput},
  author = {Doursat, René and Sayama, Hiroki and Michel, Olivier},
  urldate = {2016-12-08},
  date = {2013-12-01},
  pages = {517--535},
  file = {Full Text PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/675KUDUH/Doursat et al. - 2013 - A review of morphogenetic engineering.pdf:application/pdf;Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/ZKHIR8GJ/s11047-013-9398-1.html:text/html}
}

@article{lewandowska_recording_2015,
  title = {Recording {{Large Extracellular Spikes}} in {{Microchannels}} along {{Many Axonal Sites}} from {{Individual Neurons}}},
  volume = {10},
  issn = {1932-6203},
  url = {http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0118514},
  doi = {10.1371/journal.pone.0118514},
  abstract = {The numerous connections between neuronal cell bodies, made by their dendrites and axons, are vital for information processing in the brain. While dendrites and synapses have been extensively studied, axons have remained elusive to a large extent. We present a novel platform to study axonal physiology and information processing based on combining an 11,011-electrode high-density complementary metal-oxide semiconductor microelectrode array with a poly(dimethylsiloxane) channel device, which isolates axons from somas and, importantly, significantly amplifies recorded axonal signals. The combination of the microelectrode array with recording and stimulation capability with the microfluidic isolation channels permitted us to study axonal signal behavior at great detail. The device, featuring two culture chambers with over 30 channels spanning in between, enabled long-term recording of single spikes from isolated axons with signal amplitudes of 100 μV up to 2 mV. Propagating signals along axons could be recorded with 10 to 50 electrodes per channel. We (i) describe the performance and capabilities of our device for axonal electrophysiology, and (ii) present novel data on axonal signals facilitated by the device. Spontaneous action potentials with characteristic shapes propagated from somas along axons between the two compartments, and these unique shapes could be used to identify individual axons within channels that contained many axonal branches. Stimulation through the electrode array facilitated the identification of somas and their respective axons, enabling interfacing with different compartments of a single cell. Complex spike shapes observed in channels were traced back to single cells, and we show that more complicated spike shapes originate from a linear superposition of multiple axonal signals rather than signal distortion by the channels.},
  timestamp = {2016-12-05T15:10:38Z},
  number = {3},
  journaltitle = {PLOS ONE},
  shortjournal = {PLOS ONE},
  author = {Lewandowska, Marta K. and Bakkum, Douglas J. and Rompani, Santiago B. and Hierlemann, Andreas},
  urldate = {2016-12-05},
  date = {2015-03-03},
  pages = {e0118514},
  keywords = {Action potentials,Axons,Electrode potentials,Electrode recording,Functional electrical stimulation,Microfluidics,Neuronal dendrites,Neurons},
  file = {Full Text PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/B2NMQSGI/Lewandowska et al. - 2015 - Recording Large Extracellular Spikes in Microchann.pdf:application/pdf;Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/845DPTMN/article.html:text/html}
}

@article{newman_structure_2003,
  title = {The {{Structure}} and {{Function}} of {{Complex Networks}}},
  volume = {45},
  issn = {0036-1445},
  url = {http://epubs.siam.org/doi/abs/10.1137/S003614450342480},
  doi = {10.1137/S003614450342480},
  abstract = {Inspired by empirical studies of networked systems such as the Internet, social networks, and biological networks, researchers have in recent years developed a variety of techniques and models to help us understand or predict the behavior of these systems. Here we review developments in this field, including such concepts as the small-world effect, degree distributions, clustering, network correlations, random graph models, models of network growth and preferential attachment, and dynamical processes taking place on networks.},
  timestamp = {2016-12-04T15:49:31Z},
  number = {2},
  journaltitle = {SIAM Review},
  shortjournal = {SIAM Rev.},
  author = {Newman, M.},
  urldate = {2016-12-04},
  date = {2003-01-01},
  pages = {167--256},
  file = {Full Text PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/UEAB4EB9/Newman - 2003 - The Structure and Function of Complex Networks.pdf:application/pdf;Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/KPU2733Q/S003614450342480.html:text/html}
}

@article{pizzi_cultured_2009,
  title = {A Cultured Human Neural Network Operates a Robotic Actuator},
  volume = {95},
  issn = {0303-2647},
  url = {http://www.sciencedirect.com/science/article/pii/S0303264708001962},
  doi = {10.1016/j.biosystems.2008.09.006},
  abstract = {The development of bio-electronic prostheses, hybrid human-electronics devices and bionic robots has been the aim of many researchers. Although neurophysiologic processes have been widely investigated and bio-electronics has developed rapidly, the dynamics of a biological neuronal network that receive sensory inputs, store and control information is not yet understood. Toward this end, we have taken an interdisciplinary approach to study the learning and response of biological neural networks to complex stimulation patterns. This paper describes the design, execution, and results of several experiments performed in order to investigate the behavior of complex interconnected structures found in biological neural networks.

The experimental design consisted of biological human neurons stimulated by parallel signal patterns intended to simulate complex perceptions. The response patterns were analyzed with an innovative artificial neural network (ANN), called ITSOM (Inductive Tracing Self Organizing Map). This system allowed us to decode the complex neural responses from a mixture of different stimulations and learned memory patterns inherent in the cell colonies. In the experiment described in this work, neurons derived from human neural stem cells were connected to a robotic actuator through the ANN analyzer to demonstrate our ability to produce useful control from simulated perceptions stimulating the cells.

Preliminary results showed that in vitro human neuron colonies can learn to reply selectively to different stimulation patterns and that response signals can effectively be decoded to operate a minirobot. Lastly the fascinating performance of the hybrid system is evaluated quantitatively and potential future work is discussed.},
  timestamp = {2016-12-06T17:04:36Z},
  number = {2},
  journaltitle = {Biosystems},
  shortjournal = {Biosystems},
  author = {Pizzi, R. M. R. and Rossetti, D. and Cino, G. and Marino, D. and {A.L.Vescovi} and Baer, W.},
  urldate = {2016-12-05},
  date = {2009-02},
  pages = {137--144},
  keywords = {Artificial neural networks,Bionics,MEA,Neurons,Robot,Stem cells},
  file = {ScienceDirect Full Text PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/C6PZNKFQ/Pizzi et al. - 2009 - A cultured human neural network operates a robotic.pdf:application/pdf;ScienceDirect Full Text PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/UP5RCNIR/Pizzi et al. - 2009 - A cultured human neural network operates a robotic.pdf:application/pdf;ScienceDirect Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/CWP9NKQT/S0303264708001962.html:text/html;ScienceDirect Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/N64PN6E9/S0303264708001962.html:text/html}
}

@article{gershenson_introduction_2004,
  title = {Introduction to {{Random Boolean Networks}}},
  url = {http://arxiv.org/abs/nlin/0408006},
  abstract = {The goal of this tutorial is to promote interest in the study of random Boolean networks (RBNs). These can be very interesting models, since one does not have to assume any functionality or particular connectivity of the networks to study their generic properties. Like this, RBNs have been used for exploring the configurations where life could emerge. The fact that RBNs are a generalization of cellular automata makes their research a very important topic. The tutorial, intended for a broad audience, presents the state of the art in RBNs, spanning over several lines of research carried out by different groups. We focus on research done within artificial life, as we cannot exhaust the abundant research done over the decades related to RBNs.},
  timestamp = {2016-12-05T12:37:55Z},
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {nlin/0408006},
  author = {Gershenson, Carlos},
  urldate = {2016-12-05},
  date = {2004-08-02},
  keywords = {Computer Science - Computational Complexity,Condensed Matter - Statistical Mechanics,Nonlinear Sciences - Adaptation and Self-Organizing Systems,Nonlinear Sciences - Cellular Automata and Lattice Gases,Quantitative Biology - Molecular Networks,Quantitative Biology - Quantitative Methods},
  file = {arXiv\:nlin/0408006 PDF:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/KU7XUWA6/Gershenson - 2004 - Introduction to Random Boolean Networks.pdf:application/pdf;arXiv.org Snapshot:/home/peter/.zotero/zotero/tdejvxn7.default/zotero/storage/ZJQ67J8V/0408006.html:text/html}
}

@comment{jabref-meta: groupsversion:3;}
@comment{jabref-meta: groupstree:
0 AllEntriesGroup:;
1 ExplicitGroup:Neuromed\;0\;;
1 ExplicitGroup:technical manuals\;0\;undefined\;undefined\;;
}

